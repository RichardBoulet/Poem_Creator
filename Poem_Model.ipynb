{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poem Generation Using Web-Scraped Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this project is to generate (decent) poems from scraped website text using a keyowrd as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Poem Dataset Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "text = open('kaggle_poems.csv',encoding=\"utf8\").read()\n",
    "\n",
    "# Split each line as a sentence.\n",
    "corpus = text.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'of': 3,\n",
       " 'a': 4,\n",
       " 'to': 5,\n",
       " 'in': 6,\n",
       " 'i': 7,\n",
       " 'that': 8,\n",
       " 'is': 9,\n",
       " 'with': 10,\n",
       " 'my': 11,\n",
       " 'it': 12,\n",
       " 'you': 13,\n",
       " 'on': 14,\n",
       " 'for': 15,\n",
       " 'as': 16,\n",
       " 'his': 17,\n",
       " 'he': 18,\n",
       " 'was': 19,\n",
       " 'from': 20,\n",
       " 'not': 21,\n",
       " 'but': 22,\n",
       " 'we': 23,\n",
       " 'all': 24,\n",
       " 'her': 25,\n",
       " 'at': 26,\n",
       " 'like': 27,\n",
       " 'me': 28,\n",
       " 'or': 29,\n",
       " 'they': 30,\n",
       " 'be': 31,\n",
       " 'this': 32,\n",
       " 'by': 33,\n",
       " 'are': 34,\n",
       " 'one': 35,\n",
       " 'your': 36,\n",
       " 'their': 37,\n",
       " 'what': 38,\n",
       " 'so': 39,\n",
       " 'when': 40,\n",
       " 'no': 41,\n",
       " 'she': 42,\n",
       " 'have': 43,\n",
       " 'out': 44,\n",
       " 'there': 45,\n",
       " 'our': 46,\n",
       " 'who': 47,\n",
       " 'up': 48,\n",
       " 'if': 49,\n",
       " 'into': 50,\n",
       " 'an': 51,\n",
       " 'its': 52,\n",
       " 'where': 53,\n",
       " 'will': 54,\n",
       " 'then': 55,\n",
       " '\\xa0': 56,\n",
       " 'were': 57,\n",
       " 'now': 58,\n",
       " 'them': 59,\n",
       " 'had': 60,\n",
       " 'him': 61,\n",
       " 'which': 62,\n",
       " 'how': 63,\n",
       " 'us': 64,\n",
       " 'down': 65,\n",
       " 'through': 66,\n",
       " 'can': 67,\n",
       " 'love': 68,\n",
       " 'more': 69,\n",
       " 'would': 70,\n",
       " 'time': 71,\n",
       " '”': 72,\n",
       " 'do': 73,\n",
       " 'over': 74,\n",
       " 'back': 75,\n",
       " 'know': 76,\n",
       " 'could': 77,\n",
       " 'day': 78,\n",
       " 'some': 79,\n",
       " 'see': 80,\n",
       " 'night': 81,\n",
       " 'man': 82,\n",
       " 'amp': 83,\n",
       " 'light': 84,\n",
       " 'still': 85,\n",
       " 'has': 86,\n",
       " 'only': 87,\n",
       " 'never': 88,\n",
       " 'here': 89,\n",
       " 'life': 90,\n",
       " 'said': 91,\n",
       " 'way': 92,\n",
       " 'eyes': 93,\n",
       " 'long': 94,\n",
       " 'say': 95,\n",
       " 'old': 96,\n",
       " 'am': 97,\n",
       " 'thy': 98,\n",
       " 'each': 99,\n",
       " 'than': 100,\n",
       " 'too': 101,\n",
       " 'about': 102,\n",
       " 'come': 103,\n",
       " 'world': 104,\n",
       " 'before': 105,\n",
       " 'just': 106,\n",
       " 'go': 107,\n",
       " 'white': 108,\n",
       " 'little': 109,\n",
       " 'did': 110,\n",
       " 'other': 111,\n",
       " 'yet': 112,\n",
       " 'these': 113,\n",
       " 'even': 114,\n",
       " 'those': 115,\n",
       " 'after': 116,\n",
       " 'made': 117,\n",
       " 'first': 118,\n",
       " 'heart': 119,\n",
       " 'away': 120,\n",
       " 'been': 121,\n",
       " 'again': 122,\n",
       " 'thou': 123,\n",
       " 'let': 124,\n",
       " 'off': 125,\n",
       " 'two': 126,\n",
       " 'own': 127,\n",
       " 'black': 128,\n",
       " 'while': 129,\n",
       " 'water': 130,\n",
       " 'though': 131,\n",
       " 'hand': 132,\n",
       " 'make': 133,\n",
       " 'god': 134,\n",
       " 'face': 135,\n",
       " 'may': 136,\n",
       " 'new': 137,\n",
       " 'last': 138,\n",
       " 'every': 139,\n",
       " 'nothing': 140,\n",
       " 'once': 141,\n",
       " 'dark': 142,\n",
       " 'sun': 143,\n",
       " 'shall': 144,\n",
       " 'men': 145,\n",
       " 'dead': 146,\n",
       " 'must': 147,\n",
       " 'air': 148,\n",
       " '—': 149,\n",
       " 'under': 150,\n",
       " 'good': 151,\n",
       " 't': 152,\n",
       " 'think': 153,\n",
       " 'head': 154,\n",
       " 'things': 155,\n",
       " 'body': 156,\n",
       " 'nor': 157,\n",
       " 'death': 158,\n",
       " 'it’s': 159,\n",
       " 'such': 160,\n",
       " 'earth': 161,\n",
       " 'look': 162,\n",
       " 'left': 163,\n",
       " 'sea': 164,\n",
       " 'hands': 165,\n",
       " 'wind': 166,\n",
       " 'thee': 167,\n",
       " 'thought': 168,\n",
       " 'without': 169,\n",
       " 'much': 170,\n",
       " 'upon': 171,\n",
       " 'sky': 172,\n",
       " 'years': 173,\n",
       " 'many': 174,\n",
       " 'blue': 175,\n",
       " 'place': 176,\n",
       " 'whose': 177,\n",
       " 'because': 178,\n",
       " 'came': 179,\n",
       " 'take': 180,\n",
       " 'house': 181,\n",
       " 'home': 182,\n",
       " 'something': 183,\n",
       " 'mother': 184,\n",
       " 'well': 185,\n",
       " 'should': 186,\n",
       " 'o': 187,\n",
       " 'might': 188,\n",
       " 'another': 189,\n",
       " 'around': 190,\n",
       " 'green': 191,\n",
       " 'great': 192,\n",
       " 'why': 193,\n",
       " 'tell': 194,\n",
       " 'always': 195,\n",
       " 'people': 196,\n",
       " 'red': 197,\n",
       " 'want': 198,\n",
       " 'between': 199,\n",
       " 'against': 200,\n",
       " 'don’t': 201,\n",
       " 'ever': 202,\n",
       " 'get': 203,\n",
       " 'far': 204,\n",
       " 'saw': 205,\n",
       " 'blood': 206,\n",
       " 'name': 207,\n",
       " 'hear': 208,\n",
       " 'right': 209,\n",
       " 'being': 210,\n",
       " 'words': 211,\n",
       " 'mind': 212,\n",
       " 'sweet': 213,\n",
       " 'i’m': 214,\n",
       " 'end': 215,\n",
       " 'find': 216,\n",
       " 'high': 217,\n",
       " 'any': 218,\n",
       " 'small': 219,\n",
       " 'across': 220,\n",
       " 'fire': 221,\n",
       " 'thing': 222,\n",
       " 'trees': 223,\n",
       " 'room': 224,\n",
       " 'days': 225,\n",
       " 'woman': 226,\n",
       " 'lost': 227,\n",
       " 'same': 228,\n",
       " 'soul': 229,\n",
       " 'father': 230,\n",
       " 'hair': 231,\n",
       " 'open': 232,\n",
       " 'half': 233,\n",
       " 'cold': 234,\n",
       " 'sleep': 235,\n",
       " 'eye': 236,\n",
       " 'behind': 237,\n",
       " 'gone': 238,\n",
       " 'morning': 239,\n",
       " 'live': 240,\n",
       " 'above': 241,\n",
       " 'give': 242,\n",
       " 'until': 243,\n",
       " 'tree': 244,\n",
       " 'past': 245,\n",
       " 'full': 246,\n",
       " 'alone': 247,\n",
       " 'inside': 248,\n",
       " 'leaves': 249,\n",
       " 'voice': 250,\n",
       " 'rain': 251,\n",
       " 'door': 252,\n",
       " 'knew': 253,\n",
       " 'says': 254,\n",
       " 'children': 255,\n",
       " 'feel': 256,\n",
       " 'feet': 257,\n",
       " 'does': 258,\n",
       " 'moon': 259,\n",
       " 'most': 260,\n",
       " 'went': 261,\n",
       " 'deep': 262,\n",
       " 'bed': 263,\n",
       " 'three': 264,\n",
       " 'sound': 265,\n",
       " 'till': 266,\n",
       " 'keep': 267,\n",
       " 'among': 268,\n",
       " 'young': 269,\n",
       " 'word': 270,\n",
       " '3': 271,\n",
       " 'river': 272,\n",
       " 'dream': 273,\n",
       " 'turn': 274,\n",
       " 'myself': 275,\n",
       " 'work': 276,\n",
       " 'found': 277,\n",
       " 'heard': 278,\n",
       " 'child': 279,\n",
       " 'song': 280,\n",
       " 'enough': 281,\n",
       " 'city': 282,\n",
       " 'die': 283,\n",
       " 'call': 284,\n",
       " 'both': 285,\n",
       " 'very': 286,\n",
       " 'along': 287,\n",
       " 'snow': 288,\n",
       " 'side': 289,\n",
       " 'got': 290,\n",
       " 'seen': 291,\n",
       " 'put': 292,\n",
       " 'fall': 293,\n",
       " 'leave': 294,\n",
       " 'mouth': 295,\n",
       " 'bright': 296,\n",
       " 'e': 297,\n",
       " 'hard': 298,\n",
       " 'remember': 299,\n",
       " 'everything': 300,\n",
       " 'cannot': 301,\n",
       " 'land': 302,\n",
       " 'comes': 303,\n",
       " 'gold': 304,\n",
       " 'oh': 305,\n",
       " 'next': 306,\n",
       " 'window': 307,\n",
       " 'set': 308,\n",
       " 'walk': 309,\n",
       " 'going': 310,\n",
       " 'whole': 311,\n",
       " 'mine': 312,\n",
       " 'round': 313,\n",
       " 'boy': 314,\n",
       " 'þe': 315,\n",
       " 'rest': 316,\n",
       " 'street': 317,\n",
       " 'took': 318,\n",
       " 'ground': 319,\n",
       " 'itself': 320,\n",
       " 'stand': 321,\n",
       " 'kind': 322,\n",
       " 'stars': 323,\n",
       " 'thus': 324,\n",
       " 'glass': 325,\n",
       " 'since': 326,\n",
       " 'fear': 327,\n",
       " 'year': 328,\n",
       " 'need': 329,\n",
       " 'summer': 330,\n",
       " 'grass': 331,\n",
       " 'heaven': 332,\n",
       " 'someone': 333,\n",
       " 'sometimes': 334,\n",
       " 'hold': 335,\n",
       " 'can’t': 336,\n",
       " 'arms': 337,\n",
       " 'true': 338,\n",
       " 'read': 339,\n",
       " 'beneath': 340,\n",
       " 'stone': 341,\n",
       " 'breath': 342,\n",
       " 'whom': 343,\n",
       " 'flowers': 344,\n",
       " 'art': 345,\n",
       " 'self': 346,\n",
       " 'living': 347,\n",
       " 'done': 348,\n",
       " 'part': 349,\n",
       " 'soon': 350,\n",
       " 'called': 351,\n",
       " 'makes': 352,\n",
       " 'lie': 353,\n",
       " 'toward': 354,\n",
       " 'line': 355,\n",
       " 'skin': 356,\n",
       " 'free': 357,\n",
       " 'silence': 358,\n",
       " 'best': 359,\n",
       " 'pain': 360,\n",
       " 'beyond': 361,\n",
       " 'told': 362,\n",
       " 'wild': 363,\n",
       " 'war': 364,\n",
       " 'together': 365,\n",
       " 'human': 366,\n",
       " 'near': 367,\n",
       " 'within': 368,\n",
       " 'sing': 369,\n",
       " 'born': 370,\n",
       " 'music': 371,\n",
       " 'close': 372,\n",
       " 'else': 373,\n",
       " 'speak': 374,\n",
       " 'dust': 375,\n",
       " 'less': 376,\n",
       " 'fair': 377,\n",
       " 'girl': 378,\n",
       " 'friend': 379,\n",
       " 'rose': 380,\n",
       " 'stood': 381,\n",
       " 'lay': 382,\n",
       " 'turned': 383,\n",
       " 'birds': 384,\n",
       " 'better': 385,\n",
       " 'beautiful': 386,\n",
       " 'spring': 387,\n",
       " 'late': 388,\n",
       " 'women': 389,\n",
       " 'wall': 390,\n",
       " 'broken': 391,\n",
       " 'watch': 392,\n",
       " 'also': 393,\n",
       " 'soft': 394,\n",
       " 'almost': 395,\n",
       " 'looking': 396,\n",
       " 'moment': 397,\n",
       " 'empty': 398,\n",
       " 'few': 399,\n",
       " 'mean': 400,\n",
       " 'held': 401,\n",
       " 'yellow': 402,\n",
       " 'hope': 403,\n",
       " 'lips': 404,\n",
       " 'clear': 405,\n",
       " 'knows': 406,\n",
       " 'clouds': 407,\n",
       " 'himself': 408,\n",
       " 'dreams': 409,\n",
       " 'cut': 410,\n",
       " 'touch': 411,\n",
       " 'road': 412,\n",
       " 'winter': 413,\n",
       " 'bird': 414,\n",
       " 'beauty': 415,\n",
       " 'wings': 416,\n",
       " 'others': 417,\n",
       " 'joy': 418,\n",
       " 'hour': 419,\n",
       " 'shadow': 420,\n",
       " 'son': 421,\n",
       " 'coming': 422,\n",
       " 'space': 423,\n",
       " 'big': 424,\n",
       " 'power': 425,\n",
       " 'felt': 426,\n",
       " 'run': 427,\n",
       " 'poor': 428,\n",
       " 'gave': 429,\n",
       " 'loved': 430,\n",
       " 'flesh': 431,\n",
       " 'outside': 432,\n",
       " 'didn’t': 433,\n",
       " 'maybe': 434,\n",
       " 'field': 435,\n",
       " 'tongue': 436,\n",
       " 'book': 437,\n",
       " 'wanted': 438,\n",
       " 'waiting': 439,\n",
       " 'fingers': 440,\n",
       " 'that’s': 441,\n",
       " 'times': 442,\n",
       " 'i’ve': 443,\n",
       " 'used': 444,\n",
       " 'lord': 445,\n",
       " 'goes': 446,\n",
       " 'lives': 447,\n",
       " 'tears': 448,\n",
       " 'themselves': 449,\n",
       " 'darkness': 450,\n",
       " 'dear': 451,\n",
       " 'care': 452,\n",
       " 'sense': 453,\n",
       " 'dog': 454,\n",
       " 'ye': 455,\n",
       " 'died': 456,\n",
       " 'happy': 457,\n",
       " 'low': 458,\n",
       " 'play': 459,\n",
       " 'pass': 460,\n",
       " 'slow': 461,\n",
       " 'memory': 462,\n",
       " 'rise': 463,\n",
       " 'later': 464,\n",
       " 'ask': 465,\n",
       " 'hath': 466,\n",
       " 'four': 467,\n",
       " 'floor': 468,\n",
       " 'sit': 469,\n",
       " 'fell': 470,\n",
       " 'change': 471,\n",
       " 'town': 472,\n",
       " 'none': 473,\n",
       " 'yes': 474,\n",
       " 'friends': 475,\n",
       " 'talk': 476,\n",
       " 'spirit': 477,\n",
       " 'looked': 478,\n",
       " 'strange': 479,\n",
       " 'car': 480,\n",
       " 'stop': 481,\n",
       " 'story': 482,\n",
       " 'king': 483,\n",
       " 'perhaps': 484,\n",
       " 'sight': 485,\n",
       " 'country': 486,\n",
       " 'move': 487,\n",
       " 'gray': 488,\n",
       " 'brown': 489,\n",
       " 'truth': 490,\n",
       " 'wide': 491,\n",
       " 'seems': 492,\n",
       " 'there’s': 493,\n",
       " 'garden': 494,\n",
       " 'wood': 495,\n",
       " 'cry': 496,\n",
       " 'believe': 497,\n",
       " 'age': 498,\n",
       " 'ice': 499,\n",
       " 'evening': 500,\n",
       " 'fields': 501,\n",
       " 'forth': 502,\n",
       " 'real': 503,\n",
       " 'hours': 504,\n",
       " 'faces': 505,\n",
       " 'table': 506,\n",
       " 'nature': 507,\n",
       " 'silver': 508,\n",
       " \"it's\": 509,\n",
       " 'beside': 510,\n",
       " 'anything': 511,\n",
       " 'i’d': 512,\n",
       " 'bring': 513,\n",
       " 'already': 514,\n",
       " 'poem': 515,\n",
       " 'hot': 516,\n",
       " 'become': 517,\n",
       " 'grow': 518,\n",
       " 'eat': 519,\n",
       " 'warm': 520,\n",
       " 'sure': 521,\n",
       " 'star': 522,\n",
       " 'kept': 523,\n",
       " 'dry': 524,\n",
       " 'thousand': 525,\n",
       " 'stay': 526,\n",
       " 'bones': 527,\n",
       " 'having': 528,\n",
       " 'quiet': 529,\n",
       " 'heavy': 530,\n",
       " 'sad': 531,\n",
       " 'really': 532,\n",
       " 'looks': 533,\n",
       " 'peace': 534,\n",
       " 'þat': 535,\n",
       " 'wife': 536,\n",
       " 'write': 537,\n",
       " 'brought': 538,\n",
       " 'show': 539,\n",
       " 'wish': 540,\n",
       " 'smoke': 541,\n",
       " 'matter': 542,\n",
       " 'fish': 543,\n",
       " 'lies': 544,\n",
       " 'shadows': 545,\n",
       " 'hell': 546,\n",
       " 'making': 547,\n",
       " 'rock': 548,\n",
       " 'five': 549,\n",
       " 'golden': 550,\n",
       " 'longer': 551,\n",
       " 'paper': 552,\n",
       " 'use': 553,\n",
       " 'silent': 554,\n",
       " 'hill': 555,\n",
       " 'pale': 556,\n",
       " 'seemed': 557,\n",
       " 'thoughts': 558,\n",
       " '’': 559,\n",
       " 'form': 560,\n",
       " 'sand': 561,\n",
       " 'waves': 562,\n",
       " 'fly': 563,\n",
       " 'bodies': 564,\n",
       " 'known': 565,\n",
       " 'wrong': 566,\n",
       " '•': 567,\n",
       " 'below': 568,\n",
       " 'course': 569,\n",
       " 'falling': 570,\n",
       " 'today': 571,\n",
       " 'cloud': 572,\n",
       " 'smile': 573,\n",
       " 'second': 574,\n",
       " 'bear': 575,\n",
       " 'wait': 576,\n",
       " 'walls': 577,\n",
       " 'heat': 578,\n",
       " 'thin': 579,\n",
       " 'wet': 580,\n",
       " 'thinking': 581,\n",
       " 'strong': 582,\n",
       " 'desire': 583,\n",
       " 'legs': 584,\n",
       " 'brother': 585,\n",
       " 'you’re': 586,\n",
       " 'sat': 587,\n",
       " 'bad': 588,\n",
       " 'color': 589,\n",
       " 'smell': 590,\n",
       " \"don't\": 591,\n",
       " 'wonder': 592,\n",
       " 'try': 593,\n",
       " 'edge': 594,\n",
       " 'i’ll': 595,\n",
       " 'forget': 596,\n",
       " 'language': 597,\n",
       " 'meet': 598,\n",
       " 'ago': 599,\n",
       " 'flower': 600,\n",
       " 'dance': 601,\n",
       " 'teeth': 602,\n",
       " 'break': 603,\n",
       " 'names': 604,\n",
       " 'school': 605,\n",
       " 'given': 606,\n",
       " '2': 607,\n",
       " 'hills': 608,\n",
       " 'walking': 609,\n",
       " 'thick': 610,\n",
       " 'perfect': 611,\n",
       " 'began': 612,\n",
       " 'dawn': 613,\n",
       " 'moving': 614,\n",
       " 'front': 615,\n",
       " 'future': 616,\n",
       " 'saying': 617,\n",
       " 'takes': 618,\n",
       " 'lived': 619,\n",
       " 'singing': 620,\n",
       " 'doth': 621,\n",
       " 'grave': 622,\n",
       " 'ocean': 623,\n",
       " 'turns': 624,\n",
       " 'alive': 625,\n",
       " 'shape': 626,\n",
       " 'foot': 627,\n",
       " 'asked': 628,\n",
       " 'point': 629,\n",
       " 'lines': 630,\n",
       " 'whatever': 631,\n",
       " 'seem': 632,\n",
       " 'kiss': 633,\n",
       " 'grace': 634,\n",
       " 'blind': 635,\n",
       " 'help': 636,\n",
       " 'standing': 637,\n",
       " 'slowly': 638,\n",
       " 'grew': 639,\n",
       " 'dying': 640,\n",
       " 'often': 641,\n",
       " 'fast': 642,\n",
       " 'early': 643,\n",
       " 'breast': 644,\n",
       " 'burning': 645,\n",
       " 'de': 646,\n",
       " 'walked': 647,\n",
       " 'baby': 648,\n",
       " 'caught': 649,\n",
       " 'ah': 650,\n",
       " 'least': 651,\n",
       " 'forever': 652,\n",
       " 'lights': 653,\n",
       " \"i'm\": 654,\n",
       " 'he’s': 655,\n",
       " 'horse': 656,\n",
       " 'praise': 657,\n",
       " 'heads': 658,\n",
       " 'mountain': 659,\n",
       " 'return': 660,\n",
       " 'windows': 661,\n",
       " 'please': 662,\n",
       " 'wine': 663,\n",
       " 'brain': 664,\n",
       " 'streets': 665,\n",
       " 'arm': 666,\n",
       " 'clean': 667,\n",
       " 'pure': 668,\n",
       " 'secret': 669,\n",
       " 'ear': 670,\n",
       " 'shore': 671,\n",
       " 'mountains': 672,\n",
       " 'single': 673,\n",
       " 'thir': 674,\n",
       " 'gods': 675,\n",
       " 'hearts': 676,\n",
       " 'trying': 677,\n",
       " 'top': 678,\n",
       " 'listen': 679,\n",
       " 'pink': 680,\n",
       " 'money': 681,\n",
       " 'understand': 682,\n",
       " 'drink': 683,\n",
       " 'ten': 684,\n",
       " 'fine': 685,\n",
       " 'falls': 686,\n",
       " 'wake': 687,\n",
       " 'different': 688,\n",
       " 'cross': 689,\n",
       " 'somewhere': 690,\n",
       " 'history': 691,\n",
       " 'train': 692,\n",
       " '1': 693,\n",
       " 'everyone': 694,\n",
       " 'holy': 695,\n",
       " 'shade': 696,\n",
       " 'youth': 697,\n",
       " 'yourself': 698,\n",
       " 'sister': 699,\n",
       " '–': 700,\n",
       " 'state': 701,\n",
       " 'fruit': 702,\n",
       " 'bare': 703,\n",
       " 'woods': 704,\n",
       " 'leaf': 705,\n",
       " 'neck': 706,\n",
       " 'taken': 707,\n",
       " 'suddenly': 708,\n",
       " 'afternoon': 709,\n",
       " 'turning': 710,\n",
       " 'pleasure': 711,\n",
       " 'save': 712,\n",
       " 'quite': 713,\n",
       " 'reach': 714,\n",
       " 'naked': 715,\n",
       " 'filled': 716,\n",
       " 'ones': 717,\n",
       " 'bone': 718,\n",
       " 'flame': 719,\n",
       " 'tiny': 720,\n",
       " 'rising': 721,\n",
       " 'meant': 722,\n",
       " 'rich': 723,\n",
       " 'instead': 724,\n",
       " 'ears': 725,\n",
       " 'lake': 726,\n",
       " 'boys': 727,\n",
       " 'grief': 728,\n",
       " 'watching': 729,\n",
       " 'means': 730,\n",
       " 'glory': 731,\n",
       " 'west': 732,\n",
       " 'answer': 733,\n",
       " 'six': 734,\n",
       " 'daughter': 735,\n",
       " 'poetry': 736,\n",
       " 'large': 737,\n",
       " 'begin': 738,\n",
       " 'food': 739,\n",
       " 'family': 740,\n",
       " 'thine': 741,\n",
       " 'vain': 742,\n",
       " 'cast': 743,\n",
       " 'stones': 744,\n",
       " 'won’t': 745,\n",
       " 'passed': 746,\n",
       " 'feeling': 747,\n",
       " 'girls': 748,\n",
       " 'iron': 749,\n",
       " 'neither': 750,\n",
       " 'corner': 751,\n",
       " 'running': 752,\n",
       " 'ancient': 753,\n",
       " 'wants': 754,\n",
       " 'cool': 755,\n",
       " 'mirror': 756,\n",
       " 'salt': 757,\n",
       " 'reason': 758,\n",
       " 'except': 759,\n",
       " 'person': 760,\n",
       " 'certain': 761,\n",
       " 'learned': 762,\n",
       " 'fresh': 763,\n",
       " 'imagine': 764,\n",
       " 'middle': 765,\n",
       " 'watched': 766,\n",
       " 'knowing': 767,\n",
       " 'learn': 768,\n",
       " 'hundred': 769,\n",
       " 'stands': 770,\n",
       " 'hit': 771,\n",
       " 'houses': 772,\n",
       " 'tried': 773,\n",
       " 'north': 774,\n",
       " 'ran': 775,\n",
       " 'lot': 776,\n",
       " 'taste': 777,\n",
       " 'forest': 778,\n",
       " 'straight': 779,\n",
       " 'burn': 780,\n",
       " 'milk': 781,\n",
       " 'ring': 782,\n",
       " 'church': 783,\n",
       " 'books': 784,\n",
       " 'wear': 785,\n",
       " 'loud': 786,\n",
       " 'short': 787,\n",
       " 'path': 788,\n",
       " 'winds': 789,\n",
       " 'box': 790,\n",
       " 'whether': 791,\n",
       " 'wave': 792,\n",
       " 'step': 793,\n",
       " 'drop': 794,\n",
       " 'lady': 795,\n",
       " 'delight': 796,\n",
       " 'twenty': 797,\n",
       " 'storm': 798,\n",
       " 'ways': 799,\n",
       " 'birth': 800,\n",
       " 'throat': 801,\n",
       " 'sounds': 802,\n",
       " 'waters': 803,\n",
       " 'fate': 804,\n",
       " 'met': 805,\n",
       " 'angels': 806,\n",
       " 'poet': 807,\n",
       " 'holding': 808,\n",
       " 'voices': 809,\n",
       " 'finally': 810,\n",
       " 'tall': 811,\n",
       " 'hate': 812,\n",
       " 'grown': 813,\n",
       " 'either': 814,\n",
       " 'start': 815,\n",
       " 'moved': 816,\n",
       " 'stream': 817,\n",
       " 'gives': 818,\n",
       " 'seven': 819,\n",
       " 'sitting': 820,\n",
       " 'leaving': 821,\n",
       " 'spread': 822,\n",
       " 'kitchen': 823,\n",
       " 'distance': 824,\n",
       " 'doesn’t': 825,\n",
       " 'catch': 826,\n",
       " 'couldn’t': 827,\n",
       " 'poems': 828,\n",
       " 'nights': 829,\n",
       " 'dress': 830,\n",
       " 'laid': 831,\n",
       " 'loves': 832,\n",
       " 'clothes': 833,\n",
       " 'image': 834,\n",
       " 'steps': 835,\n",
       " 'closed': 836,\n",
       " 'view': 837,\n",
       " 'rocks': 838,\n",
       " 'force': 839,\n",
       " '“i': 840,\n",
       " 'faith': 841,\n",
       " 'herself': 842,\n",
       " 'fill': 843,\n",
       " 'follow': 844,\n",
       " 'sent': 845,\n",
       " 'taking': 846,\n",
       " 'broke': 847,\n",
       " 'east': 848,\n",
       " 'bread': 849,\n",
       " 'quick': 850,\n",
       " 'wise': 851,\n",
       " 'shot': 852,\n",
       " 'what’s': 853,\n",
       " 'purple': 854,\n",
       " 'south': 855,\n",
       " 'shut': 856,\n",
       " 'sorrow': 857,\n",
       " 'passing': 858,\n",
       " 'order': 859,\n",
       " 'shoes': 860,\n",
       " 'weight': 861,\n",
       " 'beat': 862,\n",
       " 'blow': 863,\n",
       " 'sudden': 864,\n",
       " 'kill': 865,\n",
       " 'spoke': 866,\n",
       " 'weather': 867,\n",
       " 'desert': 868,\n",
       " 'hide': 869,\n",
       " 'isn’t': 870,\n",
       " 'hidden': 871,\n",
       " 'ourselves': 872,\n",
       " 'rather': 873,\n",
       " 'seek': 874,\n",
       " 'they’re': 875,\n",
       " 'sign': 876,\n",
       " 'page': 877,\n",
       " 'flat': 878,\n",
       " 'fact': 879,\n",
       " 'common': 880,\n",
       " 'wing': 881,\n",
       " 'laugh': 882,\n",
       " 'coffee': 883,\n",
       " 'doing': 884,\n",
       " 'sees': 885,\n",
       " 'flight': 886,\n",
       " 'plain': 887,\n",
       " 'knees': 888,\n",
       " 'lovely': 889,\n",
       " 'sleeping': 890,\n",
       " 'bent': 891,\n",
       " 'carry': 892,\n",
       " 'dirt': 893,\n",
       " 'ready': 894,\n",
       " 'pride': 895,\n",
       " 'lit': 896,\n",
       " 'wasn’t': 897,\n",
       " \"'\": 898,\n",
       " 'asleep': 899,\n",
       " 'calm': 900,\n",
       " 'loose': 901,\n",
       " 'he’d': 902,\n",
       " 'became': 903,\n",
       " 'distant': 904,\n",
       " 'everywhere': 905,\n",
       " 'forgotten': 906,\n",
       " 'places': 907,\n",
       " 'ghost': 908,\n",
       " 'roof': 909,\n",
       " 'worth': 910,\n",
       " 'built': 911,\n",
       " 'writing': 912,\n",
       " 'hung': 913,\n",
       " 'race': 914,\n",
       " 'angel': 915,\n",
       " 'branches': 916,\n",
       " 'law': 917,\n",
       " 'sang': 918,\n",
       " 'gentle': 919,\n",
       " 'chair': 920,\n",
       " 'strength': 921,\n",
       " 'mud': 922,\n",
       " 'bound': 923,\n",
       " 'lift': 924,\n",
       " 'songs': 925,\n",
       " 'ere': 926,\n",
       " 'dogs': 927,\n",
       " 'lead': 928,\n",
       " 'wound': 929,\n",
       " 'seeing': 930,\n",
       " 's': 931,\n",
       " 'sick': 932,\n",
       " 'orange': 933,\n",
       " \"th'\": 934,\n",
       " 'shame': 935,\n",
       " 'opened': 936,\n",
       " 'fat': 937,\n",
       " 'prayer': 938,\n",
       " 'talking': 939,\n",
       " 'boat': 940,\n",
       " 'holds': 941,\n",
       " 'stopped': 942,\n",
       " 'ii': 943,\n",
       " 'easy': 944,\n",
       " 'proud': 945,\n",
       " 'cat': 946,\n",
       " 'simple': 947,\n",
       " 'unto': 948,\n",
       " 'keeps': 949,\n",
       " 'doors': 950,\n",
       " 'hole': 951,\n",
       " 'doubt': 952,\n",
       " 'we’re': 953,\n",
       " '4': 954,\n",
       " 'getting': 955,\n",
       " 'drive': 956,\n",
       " 'grey': 957,\n",
       " 'meaning': 958,\n",
       " 'grows': 959,\n",
       " 'taught': 960,\n",
       " 'present': 961,\n",
       " 'surface': 962,\n",
       " 'reading': 963,\n",
       " 'cried': 964,\n",
       " 'america': 965,\n",
       " 'apart': 966,\n",
       " 'wrote': 967,\n",
       " 'anyone': 968,\n",
       " 'sunlight': 969,\n",
       " 'souls': 970,\n",
       " 'shine': 971,\n",
       " 'john': 972,\n",
       " 'onto': 973,\n",
       " 'question': 974,\n",
       " \"heav'n\": 975,\n",
       " 'lose': 976,\n",
       " 'island': 977,\n",
       " 'loss': 978,\n",
       " 'bridge': 979,\n",
       " 'sharp': 980,\n",
       " 'tired': 981,\n",
       " 'news': 982,\n",
       " 'lying': 983,\n",
       " 'cup': 984,\n",
       " 'moves': 985,\n",
       " 'fallen': 986,\n",
       " 'pray': 987,\n",
       " 'fight': 988,\n",
       " 'queen': 989,\n",
       " 'glad': 990,\n",
       " 'chance': 991,\n",
       " 'buried': 992,\n",
       " 'store': 993,\n",
       " 'flies': 994,\n",
       " 'tender': 995,\n",
       " 'oft': 996,\n",
       " 'dim': 997,\n",
       " 'bit': 998,\n",
       " 'oil': 999,\n",
       " 'lonely': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peace\n"
     ]
    }
   ],
   "source": [
    "# After looking through initial word index, need to do further research on whether or not special characters and numbers affect the keras model here. \n",
    "\n",
    "print(list(tokenizer.word_index.keys())[list(tokenizer.word_index.values()).index(534)])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Values in the corpus are being combined with words before and after the next line to end up with input_sequences in for loop. Need to make sure this is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a skillful pundit coined it as a sort'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "\n",
    "input_sequences = []\n",
    "\n",
    "# Iterate through the corpus and convert the text to vectors, for each line take the results and find the length, \n",
    "# then breaking the individual sequences to smaller sequences, increasing by one word each time in the sequence, up to the total size of the sequence the function is passing over.\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 52, 4505, 32393, 2294]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_check = tokenizer.texts_to_sequences([corpus[1]])[0]\n",
    "\n",
    "token_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 52, 4505, 32393, 2294]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_check[:4 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 52, 4505], [6, 52, 4505, 32393]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking input sequences model will use\n",
    "\n",
    "input_sequences[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1744"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input sequences is very long, 3+ million in array length, might need to look at parallelizing? chunking?\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3450015"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_sum= 0\n",
    "\n",
    "for x in input_sequences:\n",
    "    seq_sum = seq_sum + 1\n",
    "\n",
    "seq_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for x in input_sequences:\n",
    "    if len(x)>50:\n",
    "        counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.115527033940432"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the percent of sequences with greater than 50 length, may help with memory constraints\n",
    "\n",
    "counter/seq_sum *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You do not actually need one-hot encoded labels, you can use integer labels with the sparse_categorical_crossentropy loss, which accepts integer labels.\n",
    "\n",
    "## This way there should not be an out of memory error. Another alternative is to make a generator (to use with fit_generator) and one-hot encode labels on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 6]\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences- \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen = 50))\n",
    "\n",
    "\n",
    "# Create predictors and label\n",
    "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "# label = ku.to_categorical(label, num_classes = total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO LOOK AT BATCH SIZE?, also changed loss function in compile section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[69067,138135] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-32546000d400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     return op(\n\u001b[0;32m-> 1068\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[0;32m--> 296\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/poem/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[69067,138135] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=50-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 7.0924 - accuracy: 0.0698\n",
      "Epoch 2/100\n",
      "571/571 [==============================] - 19s 34ms/step - loss: 6.5236 - accuracy: 0.0713\n",
      "Epoch 3/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 6.3136 - accuracy: 0.0867\n",
      "Epoch 4/100\n",
      "571/571 [==============================] - 19s 34ms/step - loss: 6.1629 - accuracy: 0.0936\n",
      "Epoch 5/100\n",
      "571/571 [==============================] - 19s 34ms/step - loss: 5.9840 - accuracy: 0.1005\n",
      "Epoch 6/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 5.8031 - accuracy: 0.1085\n",
      "Epoch 7/100\n",
      "571/571 [==============================] - 19s 34ms/step - loss: 5.6510 - accuracy: 0.1161\n",
      "Epoch 8/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 5.5278 - accuracy: 0.1209\n",
      "Epoch 9/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 5.4199 - accuracy: 0.1258\n",
      "Epoch 10/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 5.3209 - accuracy: 0.1302\n",
      "Epoch 11/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 5.2309 - accuracy: 0.1329\n",
      "Epoch 12/100\n",
      "571/571 [==============================] - 19s 33ms/step - loss: 5.1406 - accuracy: 0.1382\n",
      "Epoch 13/100\n",
      "571/571 [==============================] - 18s 32ms/step - loss: 5.0578 - accuracy: 0.1428\n",
      "Epoch 14/100\n",
      "571/571 [==============================] - 18s 32ms/step - loss: 4.9758 - accuracy: 0.1503\n",
      "Epoch 15/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.8974 - accuracy: 0.1581\n",
      "Epoch 16/100\n",
      "571/571 [==============================] - 18s 32ms/step - loss: 4.8156 - accuracy: 0.1653\n",
      "Epoch 17/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.7292 - accuracy: 0.1738\n",
      "Epoch 18/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.6597 - accuracy: 0.1769\n",
      "Epoch 19/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.5764 - accuracy: 0.1837\n",
      "Epoch 20/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.4921 - accuracy: 0.1949\n",
      "Epoch 21/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.4153 - accuracy: 0.2042\n",
      "Epoch 22/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.3389 - accuracy: 0.2114\n",
      "Epoch 23/100\n",
      "571/571 [==============================] - 18s 31ms/step - loss: 4.2574 - accuracy: 0.2215\n",
      "Epoch 24/100\n",
      "571/571 [==============================] - 17s 31ms/step - loss: 4.1832 - accuracy: 0.2318\n",
      "Epoch 25/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 4.1112 - accuracy: 0.2417\n",
      "Epoch 26/100\n",
      "571/571 [==============================] - 17s 31ms/step - loss: 4.0365 - accuracy: 0.2516\n",
      "Epoch 27/100\n",
      "571/571 [==============================] - 17s 31ms/step - loss: 3.9608 - accuracy: 0.2611\n",
      "Epoch 28/100\n",
      "571/571 [==============================] - 17s 31ms/step - loss: 3.8887 - accuracy: 0.2715\n",
      "Epoch 29/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.8238 - accuracy: 0.2834\n",
      "Epoch 30/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.7570 - accuracy: 0.2909\n",
      "Epoch 31/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.6896 - accuracy: 0.3044\n",
      "Epoch 32/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.6150 - accuracy: 0.3144\n",
      "Epoch 33/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.5531 - accuracy: 0.3281\n",
      "Epoch 34/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.4838 - accuracy: 0.3383\n",
      "Epoch 35/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.4225 - accuracy: 0.3494\n",
      "Epoch 36/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.3649 - accuracy: 0.3628\n",
      "Epoch 37/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.3003 - accuracy: 0.3733\n",
      "Epoch 38/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.2358 - accuracy: 0.3856\n",
      "Epoch 39/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.1793 - accuracy: 0.3994\n",
      "Epoch 40/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.1194 - accuracy: 0.4136\n",
      "Epoch 41/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.0687 - accuracy: 0.4242\n",
      "Epoch 42/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 3.0145 - accuracy: 0.4336\n",
      "Epoch 43/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.9575 - accuracy: 0.4418\n",
      "Epoch 44/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.9133 - accuracy: 0.4544\n",
      "Epoch 45/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.8676 - accuracy: 0.4595\n",
      "Epoch 46/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.8131 - accuracy: 0.4712\n",
      "Epoch 47/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.7570 - accuracy: 0.4874\n",
      "Epoch 48/100\n",
      "571/571 [==============================] - 17s 29ms/step - loss: 2.7166 - accuracy: 0.4941\n",
      "Epoch 49/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.6757 - accuracy: 0.5010\n",
      "Epoch 50/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.6261 - accuracy: 0.5139\n",
      "Epoch 51/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.5891 - accuracy: 0.5199\n",
      "Epoch 52/100\n",
      "571/571 [==============================] - 17s 29ms/step - loss: 2.5401 - accuracy: 0.5286\n",
      "Epoch 53/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.5042 - accuracy: 0.5365\n",
      "Epoch 54/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.4654 - accuracy: 0.5443\n",
      "Epoch 55/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.4277 - accuracy: 0.5505\n",
      "Epoch 56/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.3939 - accuracy: 0.5582\n",
      "Epoch 57/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.3562 - accuracy: 0.5663\n",
      "Epoch 58/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.3173 - accuracy: 0.5738\n",
      "Epoch 59/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.3047 - accuracy: 0.5786\n",
      "Epoch 60/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.2550 - accuracy: 0.5892\n",
      "Epoch 61/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.2258 - accuracy: 0.5944\n",
      "Epoch 62/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.1943 - accuracy: 0.5987\n",
      "Epoch 63/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.1609 - accuracy: 0.6050\n",
      "Epoch 64/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.1375 - accuracy: 0.6102\n",
      "Epoch 65/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.1039 - accuracy: 0.6187\n",
      "Epoch 66/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.0811 - accuracy: 0.6234\n",
      "Epoch 67/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.0524 - accuracy: 0.6239\n",
      "Epoch 68/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 2.0248 - accuracy: 0.6338\n",
      "Epoch 69/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.9890 - accuracy: 0.6419\n",
      "Epoch 70/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.9620 - accuracy: 0.6473\n",
      "Epoch 71/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.9430 - accuracy: 0.6503\n",
      "Epoch 72/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.9265 - accuracy: 0.6549\n",
      "Epoch 73/100\n",
      "571/571 [==============================] - 17s 29ms/step - loss: 1.8966 - accuracy: 0.6593\n",
      "Epoch 74/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.8832 - accuracy: 0.6596\n",
      "Epoch 75/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.8507 - accuracy: 0.6664\n",
      "Epoch 76/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.8335 - accuracy: 0.6698\n",
      "Epoch 77/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.8138 - accuracy: 0.6735\n",
      "Epoch 78/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.7872 - accuracy: 0.6793\n",
      "Epoch 79/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.7775 - accuracy: 0.6829\n",
      "Epoch 80/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.7534 - accuracy: 0.6864\n",
      "Epoch 81/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.7415 - accuracy: 0.6854\n",
      "Epoch 82/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.7176 - accuracy: 0.6910\n",
      "Epoch 83/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.6922 - accuracy: 0.6965\n",
      "Epoch 84/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.6761 - accuracy: 0.7010\n",
      "Epoch 85/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.6665 - accuracy: 0.7022\n",
      "Epoch 86/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.6527 - accuracy: 0.7041\n",
      "Epoch 87/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.6318 - accuracy: 0.7079\n",
      "Epoch 88/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.6195 - accuracy: 0.7104\n",
      "Epoch 89/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5897 - accuracy: 0.7173\n",
      "Epoch 90/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5812 - accuracy: 0.7151\n",
      "Epoch 91/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5762 - accuracy: 0.7196\n",
      "Epoch 92/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5460 - accuracy: 0.7245\n",
      "Epoch 93/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5350 - accuracy: 0.7261\n",
      "Epoch 94/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5238 - accuracy: 0.7289\n",
      "Epoch 95/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5675 - accuracy: 0.7137\n",
      "Epoch 96/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.5173 - accuracy: 0.7280\n",
      "Epoch 97/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.4738 - accuracy: 0.7347\n",
      "Epoch 98/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.4663 - accuracy: 0.7370\n",
      "Epoch 99/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.4435 - accuracy: 0.7407\n",
      "Epoch 100/100\n",
      "571/571 [==============================] - 17s 30ms/step - loss: 1.4441 - accuracy: 0.7412\n"
     ]
    }
   ],
   "source": [
    "#taking long time given epoch count, need to look into this and adjusting for repetitive word use in outputs when trained with only 10 epochs\n",
    "\n",
    "history = model.fit(predictors, label, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world it deaf and macbeth john purgatory satirical assay of the heather attached hollows of sonnets said he came and tulips by sylvia plath two remarkable poems by the golden haired rock star of american poetry they had left the lady of shallot by alfred lord tennyson rime of the night\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"world\"\n",
    "next_words = 50\n",
    "  \n",
    "for _ in range(next_words):\n",
    " token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    " token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    " predicted = model.predict_classes(token_list, verbose=0)\n",
    " output_word = \"\"\n",
    " for word, index in tokenizer.word_index.items():\n",
    "  if index == predicted:\n",
    "   output_word = word\n",
    "   break\n",
    " seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poem",
   "language": "python",
   "name": "poem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
